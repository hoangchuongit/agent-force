import re
import asyncio, functools
from typing import Optional
from memory.vector_memory import VectorMemory
from memory.summarizer import MemorySummarizer

class BaseAgent:
    def __init__(self, name, role, llm_client, traits=None):
        self.name = name
        self.role = role
        self.llm = llm_client
        self.traits = traits or {}
        self.memory = VectorMemory(agent_name=name)
        self.summarizer = MemorySummarizer()

    def describe_personality(self) -> str:
        trait_map = {
            "logic": "lÃ½ trÃ­",
            "empathy": "cáº£m thÃ´ng",
            "confidence": "tá»± tin",
            "neuroticism": "dá»… xÃºc Ä‘á»™ng",
            "agreeableness": "há»£p tÃ¡c"
        }
        desc = []
        for k, v in self.traits.items():
            if v > 0.7:
                desc.append(f"ráº¥t {trait_map.get(k, k)}")
            elif v > 0.4:
                desc.append(f"{trait_map.get(k, k)} vá»«a pháº£i")
            else:
                desc.append(f"Ã­t {trait_map.get(k, k)}")
        return ", ".join(desc) if desc else "lÃ½ trÃ­ vá»«a pháº£i, há»£p tÃ¡c vá»«a pháº£i"

    async def speak(self, context: str, lightweight: bool = False) -> dict:
        summary = self.summarizer.summarize(self.memory.recent_memory(5))
        related = self.memory.recall(context)

        if lightweight:
            prompt = f"Báº¡n lÃ  {self.name} ({self.role}). TÃ¬nh huá»‘ng: {context}. HÃ£y pháº£n há»“i phÃ¹ há»£p vá»›i vai trÃ²."
        else:
            prompt = (
                f"Báº¡n lÃ  {self.name} ({self.role}).\n"
                f"TÃ­nh cÃ¡ch: {self.describe_personality()}.\n"
                f"TÃ¬nh huá»‘ng hiá»‡n táº¡i: {context}\n"
                f"KÃ½ á»©c gáº§n Ä‘Ã¢y:{summary}\n"
                f"KÃ½ á»©c liÃªn quan:{related}\n"
                f"HÃ£y pháº£n há»“i phÃ¹ há»£p vá»›i vai trÃ² vÃ  kÃ½ á»©c báº¡n cÃ³."
            )

        loop = asyncio.get_running_loop()
        response = await loop.run_in_executor(None, functools.partial(self.llm.chat, prompt))

        self.memory.remember(response)

        match = re.search(r"\((.*?)\)\s*$", response)
        speech_type = match.group(1) if match else "n/a"

        return {
            "text": response.strip(),
            "type": speech_type,
            "agent": self.name,
        }

    async def reaction_phase(self, previous_speech: str) -> Optional[dict]:
        prompt = (
            f"Má»™t agent vá»«a nÃ³i: '{previous_speech}'\n"
            f"{self.name} cÃ³ muá»‘n pháº£n á»©ng khÃ´ng? Náº¿u cÃ³, hÃ£y pháº£n há»“i ngáº¯n vÃ  ghi rÃµ loáº¡i pháº£n á»©ng trong ngoáº·c."
        )
        loop = asyncio.get_running_loop()
        response = await loop.run_in_executor(None, functools.partial(self.llm.chat, prompt))

        self.memory.remember(response)

        match = re.search(r"\((.*?)\)\s*$", response)
        speech_type = match.group(1) if match else "reaction"

        return {
            "text": response.strip(),
            "type": speech_type,
            "agent": self.name
        }

    async def stream_response(self, context: str, lightweight: bool = False):
        summary = self.summarizer.summarize(self.memory.recent_memory(5))
        related = self.memory.recall(context)

        if lightweight:
            prompt = f"Báº¡n lÃ  {self.name} ({self.role}). TÃ¬nh huá»‘ng: {context}. HÃ£y pháº£n há»“i phÃ¹ há»£p vá»›i vai trÃ²."
        else:
            prompt = (
                f"Báº¡n lÃ  {self.name} ({self.role}).\n"
                f"TÃ­nh cÃ¡ch: {self.describe_personality()}.\n"
                f"TÃ¬nh huá»‘ng hiá»‡n táº¡i: {context}\n"
                f"KÃ½ á»©c gáº§n Ä‘Ã¢y:\n{summary}\n"
                f"KÃ½ á»©c liÃªn quan:\n{related}\n"
                f"HÃ£y pháº£n há»“i phÃ¹ há»£p vá»›i vai trÃ² vÃ  kÃ½ á»©c báº¡n cÃ³."
            )
        async for chunk in self.llm.chat_stream(prompt):
            yield chunk

    def build_review_prompt(self, peer_outputs: dict) -> str:
        peer_view = "\n\n".join(f"- {name}:\n{text}" for name, text in peer_outputs.items())

        return (
            f"Báº¡n lÃ  {self.name} â€“ chuyÃªn gia trong lÄ©nh vá»±c {self.role}.\n\n"
            f"CÃ¡c bá»™ pháº­n khÃ¡c Ä‘Ã£ Ä‘Æ°a ra cÃ¡c Ã½ kiáº¿n sau:\n{peer_view}\n\n"
            "ğŸ¯ YÃªu cáº§u:\n"
            "- Náº¿u **Ä‘á»“ng thuáº­n hoÃ n toÃ n**, chá»‰ cáº§n viáº¿t: 'TÃ´i Ä‘á»“ng thuáº­n vá»›i cÃ¡c Ã½ kiáº¿n trÃªn.'\n"
            "- Náº¿u cÃ³ **pháº£n biá»‡n**, chá»‰ nÃªu rÃµ cÃ¡c Ä‘iá»ƒm cá»¥ thá»ƒ cáº§n gÃ³p Ã½.\n"
            "- KhÃ´ng tÃ³m táº¯t láº¡i Ã½ kiáº¿n cá»§a ngÆ°á»i khÃ¡c. KhÃ´ng viáº¿t láº¡i toÃ n bá»™ ná»™i dung.\n"
            "- TrÃ¡nh dÃ i dÃ²ng. Tráº£ lá»i sÃºc tÃ­ch nhÆ° má»™t chuyÃªn gia.\n\n"
            "âœï¸ Pháº£n há»“i cá»§a báº¡n:"
        )

    async def review_peer_outputs(self, peer_outputs: dict):
        prompt = self.build_review_prompt(peer_outputs)
        async for chunk in self.llm.chat_stream(prompt):
            yield chunk

    async def propose_final_action(self, peer_outputs: dict):
        opinions_text = "\n".join(f"{name}:\n{text}" for name, text in peer_outputs.items())
        prompt = (
            f"Báº¡n lÃ  {self.role}. Sau Ä‘Ã¢y lÃ  cÃ¡c Ã½ kiáº¿n tá»« cÃ¡c bá»™ pháº­n liÃªn quan trong cuá»™c há»p xá»­ lÃ½ khá»§ng hoáº£ng:\n\n"
            f"{opinions_text}\n\n"
            f"Dá»±a trÃªn cÃ¡c Ã½ kiáº¿n nÃ y, báº¡n hÃ£y Ä‘á» xuáº¥t phÆ°Æ¡ng Ã¡n hÃ nh Ä‘á»™ng cuá»‘i cÃ¹ng (1â€“3 bÆ°á»›c cá»¥ thá»ƒ) tá»« gÃ³c nhÃ¬n cá»§a mÃ¬nh."
        )
        async for chunk in self.llm.chat_stream(prompt):
            yield chunk
            
    async def handle_action_stream(self, action: dict):
        message = f"ğŸ¤– [{self.name}] Äang xá»­ lÃ½ action: {action['type']} â†’ {action.get('content', '')[:50]}..."
        yield message
        # CÃ³ thá»ƒ thÃªm xá»­ lÃ½ mÃ´ phá»ng thá»±c táº¿ táº¡i Ä‘Ã¢y (gá»­i API, sinh ná»™i dung, v.v.)
        yield f"âœ… [{self.name}] HoÃ n táº¥t xá»­ lÃ½: {action['type']}"

