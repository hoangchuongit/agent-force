from collections import Counter
from agents.roles.pragent import PRAgent
from agents.roles.legalagent import LegalAgent
from agents.roles.financeagent import FinanceAgent
from agents.roles.opsagent import OpsAgent
from agents.roles.criticalagent import CriticalAgent
from orchestrator.action_extractor import extract_actions_stream
from orchestrator.executor import execute_actions_stream
from orchestrator.goal_manager import GoalManager


class DeliberationOrchestrator:
    CONSENSUS_PHRASE = "t√¥i ƒë·ªìng thu·∫≠n v·ªõi c√°c √Ω ki·∫øn tr√™n."

    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.core_agents = [
            PRAgent(llm_client),
            LegalAgent(llm_client),
            FinanceAgent(llm_client),
            OpsAgent(llm_client),
        ]
        self.critical_agent = CriticalAgent(llm_client)

        self.agents = self.core_agents + [self.critical_agent]  # Critical lu√¥n ph·∫£n bi·ªán nh∆∞ng kh√¥ng lead s·ªõm

        default_goals = GoalManager.get_default_goals()
        for agent in self.agents:
            agent_key = type(agent).__name__
            agent.set_goal(default_goals.get(agent_key, ""))

    def score_agents(self, context: str):
        context_lower = context.lower()
        keyword_map = GoalManager.KEYWORD_GOALS
        scores = []
        for agent in self.core_agents:
            agent_key = type(agent).__name__
            keywords = keyword_map.get(agent_key, [])
            score = sum(1 for kw in keywords if kw in context_lower)
            scores.append((agent, score))
        return sorted(scores, key=lambda x: x[1], reverse=True)

    async def run(self, context: str, max_rounds: int = 10, max_cycles: int = 5):
        goals = GoalManager.extract_goals_from_context(context)
        for agent in self.agents:
            agent_key = type(agent).__name__
            new_goal = goals.get(agent_key)
            if new_goal:
                agent.set_goal(new_goal)

        agent_scores = self.score_agents(context)
        tried_agents = set()
        cycle = 0
        soft_consensus_streak = 0

        while cycle < max_cycles:
            lead_agent = next((a for a, _ in agent_scores if type(a).__name__ not in tried_agents), None)

            # Sau 3 chu k·ª≥ ‚Üí cho ph√©p CriticalAgent l√†m lead n·∫øu ch∆∞a th·ª≠
            if not lead_agent and cycle >= 3 and type(self.critical_agent).__name__ not in tried_agents:
                lead_agent = self.critical_agent

            if not lead_agent:
                break
            tried_agents.add(type(lead_agent).__name__)
            cycle += 1

            context_with_goal = lead_agent.get_goal_context() + context
            lead_response = await lead_agent.speak(context_with_goal)
            yield {"agent": lead_agent.name, "text": lead_response["text"], "type": "lead"}
            opinions = {lead_agent.name: lead_response["text"]}

            for round_num in range(max_rounds):
                round_reviews = {}
                soft_flags = []

                merged_input = "\n".join([f"{k}:\n{v}" for k, v in opinions.items()])
                merged_prompt = (
                    "T·ªïng h·ª£p n·ªôi dung sau th√†nh m·ªôt ƒë·ªÅ xu·∫•t r√µ r√†ng, lo·∫°i b·ªè tr√πng l·∫∑p, gi·ªØ m·∫°ch logic:\n\n"
                    f"{merged_input}\n\nƒê·ªÅ xu·∫•t t·ªïng h·ª£p:"
                )
                merged_opinion = ""
                async for chunk in self.llm_client.chat_stream(merged_prompt):
                    merged_opinion += chunk

                yield {
                    "agent": "orchestrator",
                    "text": merged_opinion,
                    "type": f"merged_proposal_cycle_{cycle}_round_{round_num+1}",
                }

                for agent in self.agents:
                    try:
                        buffer = ""
                        prompt = agent.get_goal_context() + merged_opinion
                        async for chunk in agent.review_peer_outputs({"full_input": prompt}):
                            buffer += chunk
                            yield {
                                "agent": agent.name,
                                "text": chunk,
                                "type": f"stream_review_cycle_{cycle}_round_{round_num+1}",
                            }
                        review_text = buffer.strip()
                        round_reviews[agent.name] = review_text
                        yield {
                            "agent": agent.name,
                            "text": review_text,
                            "type": f"review_cycle_{cycle}_round_{round_num+1}",
                        }

                        if any(word in review_text.lower() for word in ["kh√¥ng ƒë·ªìng √Ω", "ph·∫£n ƒë·ªëi", "ƒë·ªÅ ngh·ªã xem x√©t l·∫°i"]):
                            soft_flags.append(False)
                        else:
                            soft_flags.append(True)

                    except Exception as e:
                        round_reviews[agent.name] = f"[L·ªñI khi ph·∫£n bi·ªán]: {e}"
                        soft_flags.append(False)

                if all(soft_flags):
                    soft_consensus_streak += 1
                else:
                    soft_consensus_streak = 0

                if soft_consensus_streak >= 2:
                    yield {
                        "agent": "orchestrator",
                        "text": f"‚úÖ ƒê·∫°t soft consensus sau 2 v√≤ng li√™n ti·∫øp.",
                        "type": "soft_consensus_reached",
                    }
                    async for chunk in self._finalize(merged_opinion):
                        yield chunk
                    return

                opinions = round_reviews.copy()

            proposal_counter = Counter(opinions.values())
            most_common = proposal_counter.most_common(1)[0] if proposal_counter else None
            if most_common and most_common[1] >= 3:
                yield {
                    "agent": "orchestrator",
                    "text": f"üìå Ph∆∞∆°ng √°n ƒë∆∞·ª£c ƒëa s·ªë (>=3) ƒë·ªìng thu·∫≠n sau chu k·ª≥ {cycle}:\n{most_common[0]}",
                    "type": "final_decision",
                }
                async for chunk in self._finalize(most_common[0]):
                    yield chunk
                return
            else:
                yield {
                    "agent": "orchestrator",
                    "text": f"‚ö†Ô∏è Ch∆∞a ƒë·∫°t ƒë·ªìng thu·∫≠n sau {max_rounds} v√≤ng. Chuy·ªÉn sang lead agent kh√°c.",
                    "type": "no_consensus",
                }

        yield {
            "agent": "orchestrator",
            "text": "‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ agent lead nh∆∞ng kh√¥ng ƒë·∫°t ƒë∆∞·ª£c ƒë·ªìng thu·∫≠n.",
            "type": "final_decision_failed",
        }

        fallback_proposal = ""
        async for chunk in self.synthesize_best_effort(opinions):
            fallback_proposal += chunk
            yield {"agent": "orchestrator", "text": chunk, "type": "final_fallback_summary"}

        async for chunk in self._finalize(fallback_proposal):
            yield chunk

    async def summarize_final_proposal(self, opinions: dict) -> str:
        merged = "\n\n".join([f"{agent}:\n{content}" for agent, content in opinions.items()])
        prompt = (
            "T√¨nh hu·ªëng: C√°c b·ªô ph·∫≠n chuy√™n m√¥n ƒë√£ ho√†n to√†n ƒë·ªìng thu·∫≠n sau nhi·ªÅu v√≤ng ph·∫£n bi·ªán.\n"
            "D∆∞·ªõi ƒë√¢y l√† c√°c √Ω ki·∫øn cu·ªëi c√πng c·ªßa t·ª´ng b·ªô ph·∫≠n:\n\n"
            f"{merged}\n\n"
            "üéØ Y√™u c·∫ßu:\n"
            "- T·ªïng h·ª£p c√°c √Ω ki·∫øn tr√™n th√†nh **m·ªôt b·∫£n ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông th·ªëng nh·∫•t**.\n"
            "- Ng·∫Øn g·ªçn, r√µ r√†ng, mang t√≠nh th·ª±c thi cao.\n"
            "- D√πng gi·ªçng vƒÉn chuy√™n nghi·ªáp, nh·∫•t qu√°n, ph√π h·ª£p ƒë·ªÉ g·ª≠i cho kh√°ch h√†ng, ƒë·ªëi t√°c ho·∫∑c c√¥ng b·ªë n·ªôi b·ªô.\n"
            "- Tr√°nh l·∫∑p l·∫°i, kh√¥ng li·ªát k√™ theo agent. Kh√¥ng c·∫ßn n√≥i 'PRAgent n√≥i r·∫±ng...'\n"
            "- N·∫øu ph√π h·ª£p, h√£y vi·∫øt d∆∞·ªõi d·∫°ng th√¥ng b√°o ch√≠nh th·ª©c ho·∫∑c email d·ª± th·∫£o.\n\n"
            "‚úçÔ∏è B·∫Øt ƒë·∫ßu b·∫£n ƒë·ªÅ xu·∫•t:"
        )
        yield "üìÑ B·∫£n ƒë·ªÅ xu·∫•t th·ªëng nh·∫•t:\n"
        async for chunk in self.llm_client.chat_stream(prompt):
            yield chunk

    async def synthesize_best_effort(self, opinions: dict) -> str:
        merged = "\n\n".join(f"{agent}:\n{text}" for agent, text in opinions.items())
        prompt = (
            "B·ªëi c·∫£nh: H·ªá th·ªëng AI g·ªìm nhi·ªÅu b·ªô ph·∫≠n chuy√™n m√¥n (PR, Ph√°p l√Ω, T√†i ch√≠nh, V·∫≠n h√†nh) ƒë√£ tranh lu·∫≠n nhi·ªÅu v√≤ng nh∆∞ng **kh√¥ng ƒë·∫°t ƒë∆∞·ª£c ƒë·ªìng thu·∫≠n ho√†n to√†n**.\n"
            "D∆∞·ªõi ƒë√¢y l√† c√°c √Ω ki·∫øn cu·ªëi c√πng c·ªßa t·ª´ng b·ªô ph·∫≠n:\n\n"
            f"{merged}\n\n"
            "üéØ Nhi·ªám v·ª•:\n"
            "- T·ªïng h·ª£p l·∫°i **c√°c ƒëi·ªÉm chung c√≥ gi√° tr·ªã cao nh·∫•t**.\n"
            "- B·ªè qua c√°c ƒëi·ªÉm tranh c√£i kh√¥ng th·ªÉ th·ªëng nh·∫•t.\n"
            "- Vi·∫øt m·ªôt **b·∫£n ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông** r√µ r√†ng, chuy√™n nghi·ªáp, trung l·∫≠p, c√≥ th·ªÉ g·ª≠i cho c·∫•p qu·∫£n l√Ω ra quy·∫øt ƒë·ªãnh.\n"
            "- Gi·ªØ vƒÉn phong kh√°ch quan, tr√°nh quy tr√°ch nhi·ªám c√° nh√¢n, tr√°nh thu·∫≠t l·∫°i ai n√≥i g√¨.\n"
            "- N·∫øu c·∫ßn, ph√¢n t√°ch th√†nh c√°c ph·∫ßn: T√¨nh h√¨nh ‚Äì H√†nh ƒë·ªông ‚Äì Khuy·∫øn ngh·ªã.\n\n"
            "‚úçÔ∏è B·∫Øt ƒë·∫ßu vi·∫øt b·∫£n ƒë·ªÅ xu·∫•t:"
        )
        yield "üìÑ B·∫£n ƒë·ªÅ xu·∫•t t·ªïng h·ª£p (fallback):\n"
        async for chunk in self.llm_client.chat_stream(prompt):
            yield chunk

    async def _finalize(self, final_proposal: str):
        yield {
            "agent": "orchestrator",
            "text": final_proposal,
            "type": "final_proposal",
        }

        action_buffer = ""
        async for chunk in extract_actions_stream(self.llm_client, final_proposal):
            action_buffer += chunk
            yield {"agent": "orchestrator", "text": chunk, "type": "action_extraction"}

        try:
            actions = eval(action_buffer)
        except Exception as e:
            yield {
                "agent": "orchestrator",
                "text": f"‚ùå L·ªói parse actions: {e}",
                "type": "error",
            }
            return

        async for chunk in execute_actions_stream(self.llm_client, actions):
            yield {"agent": "orchestrator", "text": chunk, "type": "action_execution"}
