from collections import Counter
from agents.roles.pragent import PRAgent
from agents.roles.legalagent import LegalAgent
from agents.roles.financeagent import FinanceAgent
from agents.roles.opsagent import OpsAgent
from orchestrator.action_extractor import extract_actions_stream
from orchestrator.executor import execute_actions_stream
from orchestrator.goal_manager import GoalManager


class DeliberationOrchestrator:
    CONSENSUS_PHRASE = "t√¥i ƒë·ªìng thu·∫≠n v·ªõi c√°c √Ω ki·∫øn tr√™n."

    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.agents = [
            PRAgent(llm_client),
            LegalAgent(llm_client),
            FinanceAgent(llm_client),
            OpsAgent(llm_client),
        ]

        default_goals = GoalManager.get_default_goals()
        for agent in self.agents:
            agent.set_goal(default_goals.get(agent.name, ""))

    def score_agents(self, context: str):
        context_lower = context.lower()
        keyword_map = {
            "PRAgent": [
                "truy·ªÅn th√¥ng",
                "kh√°ch h√†ng",
                "d∆∞ lu·∫≠n",
                "b√°o ch√≠",
                "ph·∫£n h·ªìi",
                "tuy√™n b·ªë",
                "xin l·ªói",
            ],
            "LegalAgent": [
                "ph√°p l√Ω",
                "vi ph·∫°m",
                "lu·∫≠t",
                "quy ƒë·ªãnh",
                "tr√°ch nhi·ªám",
                "ki·ªán t·ª•ng",
                "tu√¢n th·ªß",
            ],
            "FinanceAgent": [
                "t√†i ch√≠nh",
                "ti·ªÅn",
                "thi·ªát h·∫°i",
                "b·ªìi th∆∞·ªùng",
                "b√°o c√°o",
                "chi ph√≠",
                "l·ªó",
                "doanh thu",
            ],
            "OpsAgent": [
                "h·ªá th·ªëng",
                "v·∫≠n h√†nh",
                "s·ª± c·ªë",
                "h·∫° t·∫ßng",
                "r√≤ r·ªâ",
                "server",
                "k·ªπ thu·∫≠t",
                "kh·∫Øc ph·ª•c",
            ],
        }
        scores = []
        for agent in self.agents:
            agent_key = type(agent).__name__
            keywords = keyword_map.get(agent_key, [])
            score = sum(1 for kw in keywords if kw in context_lower)
            scores.append((agent, score))
        return sorted(scores, key=lambda x: x[1], reverse=True)

    async def run(self, context: str, max_rounds: int = 5, max_cycles: int = 2):
        goals = GoalManager.extract_goals_from_context(context)
        for agent in self.agents:
            new_goal = goals.get(agent.name)
            if new_goal:
                agent.set_goal(new_goal)

        agent_scores = self.score_agents(context)
        tried_agents = set()
        cycle = 0

        while cycle < max_cycles:
            lead_agent = next(
                (a for a, _ in agent_scores if a.name not in tried_agents), None
            )
            if not lead_agent:
                break
            tried_agents.add(lead_agent.name)
            cycle += 1

            # üëâ G·∫Øn th√™m m·ª•c ti√™u v√†o prompt ƒë·∫ßu v√†o c·ªßa agent
            context_with_goal = lead_agent.get_goal_context() + context
            lead_response = await lead_agent.speak(context_with_goal)
            yield {
                "agent": lead_agent.name,
                "text": lead_response["text"],
                "type": "lead",
            }

            opinions = {lead_agent.name: lead_response["text"]}

            for round_num in range(max_rounds):
                round_reviews = {}
                round_result = []

                for agent in self.agents:
                    try:
                        buffer = ""
                        # üëâ G·∫Øn m·ª•c ti√™u v√†o prompt tranh lu·∫≠n
                        agent_input = agent.get_goal_context() + "\n".join(
                            [f"{k}: {v}" for k, v in opinions.items()]
                        )
                        async for chunk in agent.review_peer_outputs(
                            {"full_input": agent_input}
                        ):
                            buffer += chunk
                            yield {
                                "agent": agent.name,
                                "text": chunk,
                                "type": f"stream_review_cycle_{cycle}_round_{round_num+1}",
                            }
                        review_text = buffer.strip()
                        round_reviews[agent.name] = review_text
                        round_result.append(
                            {
                                "agent": agent.name,
                                "text": review_text,
                                "type": f"review_cycle_{cycle}_round_{round_num+1}",
                            }
                        )
                    except Exception as e:
                        round_result.append(
                            {
                                "agent": agent.name,
                                "text": f"[L·ªñI khi ph·∫£n bi·ªán]: {e}",
                                "type": f"review_error_cycle_{cycle}_round_{round_num+1}",
                            }
                        )

                for r in round_result:
                    yield r

                # ‚úÖ K·∫øt th√∫c s·ªõm n·∫øu t·∫•t c·∫£ ph·∫£n h·ªìi l√† c√¢u ƒë·ªìng thu·∫≠n chu·∫©n h√≥a
                normalized = [text.lower().strip() for text in round_reviews.values()]
                if all(t == self.CONSENSUS_PHRASE for t in normalized):
                    yield {
                        "agent": "orchestrator",
                        "text": f"‚úÖ T·∫•t c·∫£ agent ƒë·ªìng thu·∫≠n s·ªõm ·ªü v√≤ng {round_num+1} (chu k·ª≥ {cycle}).",
                        "type": "final_decision",
                    }

                    # 1. T·ªïng h·ª£p b·∫£n ƒë·ªÅ xu·∫•t
                    final_proposal = ""
                    async for chunk in self.summarize_final_proposal(opinions):
                        final_proposal += chunk
                        yield {
                            "agent": "orchestrator",
                            "text": chunk,
                            "type": "final_proposal",
                        }

                    # 2. Tr√≠ch xu·∫•t h√†nh ƒë·ªông t·ª´ final_proposal
                    action_buffer = ""  # ‚úÖ Kh·ªüi t·∫°o tr∆∞·ªõc khi s·ª≠ d·ª•ng
                    async for chunk in extract_actions_stream(
                        self.llm_client, final_proposal
                    ):
                        action_buffer += chunk
                        yield {
                            "agent": "orchestrator",
                            "text": chunk,
                            "type": "action_extraction",
                        }

                    try:
                        actions = eval(action_buffer)
                    except Exception as e:
                        yield {
                            "agent": "orchestrator",
                            "text": f"‚ùå L·ªói parse actions: {e}",
                            "type": "error",
                        }
                        return

                    # 3. Th·ª±c thi h√†nh ƒë·ªông qua agent t∆∞∆°ng ·ª©ng
                    async for chunk in execute_actions_stream(self.llm_client, actions):
                        yield {
                            "agent": "orchestrator",
                            "text": chunk,
                            "type": "action_execution",
                        }

                opinions = round_reviews.copy()

            # ‚úÖ N·∫øu h·∫øt v√≤ng m√† v·∫´n ch∆∞a ƒë·ªìng thu·∫≠n ho√†n to√†n ‚Üí t√¨m ƒëa s·ªë
            proposal_counter = Counter(opinions.values())
            most_common = (
                proposal_counter.most_common(1)[0] if proposal_counter else None
            )

            if most_common and most_common[1] >= 3:
                yield {
                    "agent": "orchestrator",
                    "text": f"üìå Ph∆∞∆°ng √°n ƒë∆∞·ª£c ƒëa s·ªë (>=3) ƒë·ªìng thu·∫≠n sau chu k·ª≥ {cycle}:\n{most_common[0]}",
                    "type": "final_decision",
                }
                return
            else:
                yield {
                    "agent": "orchestrator",
                    "text": f"‚ö†Ô∏è Ch∆∞a ƒë·∫°t ƒë·ªìng thu·∫≠n sau {max_rounds} v√≤ng (chu k·ª≥ {cycle}). Chuy·ªÉn lead agent kh√°c ƒë·ªÉ ti·∫øp t·ª•c tranh lu·∫≠n.",
                    "type": "no_consensus",
                }

        yield {
            "agent": "orchestrator",
            "text": "‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ agent lead nh∆∞ng kh√¥ng ƒë·∫°t ƒë∆∞·ª£c ƒë·ªìng thu·∫≠n.",
            "type": "final_decision_failed",
        }

        # G·ªçi synthesize fallback n·∫øu c√≥ opinions
        if opinions:
            fallback_proposal = ""
            async for chunk in self.synthesize_best_effort(opinions):
                fallback_proposal += chunk
                yield {
                    "agent": "orchestrator",
                    "text": chunk,
                    "type": "final_fallback_summary",
                }

            # üëâ Ph√¢n t√≠ch h√†nh ƒë·ªông t·ª´ fallback_proposal
            action_buffer = ""  # ‚úÖ C≈©ng c·∫ßn kh·ªüi t·∫°o t·∫°i ƒë√¢y
            async for chunk in extract_actions_stream(
                self.llm_client, fallback_proposal
            ):
                action_buffer += chunk
                yield {
                    "agent": "orchestrator",
                    "text": chunk,
                    "type": "action_extraction",
                }

            try:
                actions = eval(action_buffer)
            except Exception as e:
                yield {
                    "agent": "orchestrator",
                    "text": f"‚ùå L·ªói parse fallback actions: {e}",
                    "type": "error",
                }
                return

            async for chunk in execute_actions_stream(self.llm_client, actions):
                yield {
                    "agent": "orchestrator",
                    "text": chunk,
                    "type": "action_execution",
                }

    async def summarize_final_proposal(self, opinions: dict) -> str:
        merged = "\n\n".join(
            [f"{agent}:\n{content}" for agent, content in opinions.items()]
        )

        prompt = (
            "T√¨nh hu·ªëng: C√°c b·ªô ph·∫≠n chuy√™n m√¥n ƒë√£ ho√†n to√†n ƒë·ªìng thu·∫≠n sau nhi·ªÅu v√≤ng ph·∫£n bi·ªán.\n"
            "D∆∞·ªõi ƒë√¢y l√† c√°c √Ω ki·∫øn cu·ªëi c√πng c·ªßa t·ª´ng b·ªô ph·∫≠n:\n\n"
            f"{merged}\n\n"
            "üéØ Y√™u c·∫ßu:\n"
            "- T·ªïng h·ª£p c√°c √Ω ki·∫øn tr√™n th√†nh **m·ªôt b·∫£n ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông th·ªëng nh·∫•t**.\n"
            "- Ng·∫Øn g·ªçn, r√µ r√†ng, mang t√≠nh th·ª±c thi cao.\n"
            "- D√πng gi·ªçng vƒÉn chuy√™n nghi·ªáp, nh·∫•t qu√°n, ph√π h·ª£p ƒë·ªÉ g·ª≠i cho kh√°ch h√†ng, ƒë·ªëi t√°c ho·∫∑c c√¥ng b·ªë n·ªôi b·ªô.\n"
            "- Tr√°nh l·∫∑p l·∫°i, kh√¥ng li·ªát k√™ theo agent. Kh√¥ng c·∫ßn n√≥i 'PRAgent n√≥i r·∫±ng...'\n"
            "- N·∫øu ph√π h·ª£p, h√£y vi·∫øt d∆∞·ªõi d·∫°ng th√¥ng b√°o ch√≠nh th·ª©c ho·∫∑c email d·ª± th·∫£o.\n\n"
            "‚úçÔ∏è B·∫Øt ƒë·∫ßu b·∫£n ƒë·ªÅ xu·∫•t:"
        )

        # Header m·ªü ƒë·∫ßu
        yield "üìÑ B·∫£n ƒë·ªÅ xu·∫•t th·ªëng nh·∫•t:\n"
        # Stream n·ªôi dung t·ª´ LLM
        async for chunk in self.llm_client.chat_stream(prompt):
            yield chunk

    async def synthesize_best_effort(self, opinions: dict) -> str:
        merged = "\n\n".join(f"{agent}:\n{text}" for agent, text in opinions.items())

        prompt = (
            "B·ªëi c·∫£nh: H·ªá th·ªëng AI g·ªìm nhi·ªÅu b·ªô ph·∫≠n chuy√™n m√¥n (PR, Ph√°p l√Ω, T√†i ch√≠nh, V·∫≠n h√†nh) ƒë√£ tranh lu·∫≠n nhi·ªÅu v√≤ng nh∆∞ng **kh√¥ng ƒë·∫°t ƒë∆∞·ª£c ƒë·ªìng thu·∫≠n ho√†n to√†n**.\n"
            "D∆∞·ªõi ƒë√¢y l√† c√°c √Ω ki·∫øn cu·ªëi c√πng c·ªßa t·ª´ng b·ªô ph·∫≠n:\n\n"
            f"{merged}\n\n"
            "üéØ Nhi·ªám v·ª•:\n"
            "- T·ªïng h·ª£p l·∫°i **c√°c ƒëi·ªÉm chung c√≥ gi√° tr·ªã cao nh·∫•t**.\n"
            "- B·ªè qua c√°c ƒëi·ªÉm tranh c√£i kh√¥ng th·ªÉ th·ªëng nh·∫•t.\n"
            "- Vi·∫øt m·ªôt **b·∫£n ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông** r√µ r√†ng, chuy√™n nghi·ªáp, trung l·∫≠p, c√≥ th·ªÉ g·ª≠i cho c·∫•p qu·∫£n l√Ω ra quy·∫øt ƒë·ªãnh.\n"
            "- Gi·ªØ vƒÉn phong kh√°ch quan, tr√°nh quy tr√°ch nhi·ªám c√° nh√¢n, tr√°nh thu·∫≠t l·∫°i ai n√≥i g√¨.\n"
            "- N·∫øu c·∫ßn, ph√¢n t√°ch th√†nh c√°c ph·∫ßn: T√¨nh h√¨nh ‚Äì H√†nh ƒë·ªông ‚Äì Khuy·∫øn ngh·ªã.\n\n"
            "‚úçÔ∏è B·∫Øt ƒë·∫ßu vi·∫øt b·∫£n ƒë·ªÅ xu·∫•t:"
        )

        yield "üìÑ B·∫£n ƒë·ªÅ xu·∫•t t·ªïng h·ª£p (fallback):\n"
        async for chunk in self.llm_client.chat_stream(prompt):
            yield chunk
