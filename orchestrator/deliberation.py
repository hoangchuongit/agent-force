from collections import Counter
from agents.roles.pragent import PRAgent
from agents.roles.legalagent import LegalAgent
from agents.roles.financeagent import FinanceAgent
from agents.roles.opsagent import OpsAgent
from orchestrator.action_extractor import extract_actions_stream
from orchestrator.executor import execute_actions_stream
from orchestrator.goal_manager import GoalManager


class DeliberationOrchestrator:
    CONSENSUS_PHRASE = "t√¥i ƒë·ªìng thu·∫≠n v·ªõi c√°c √Ω ki·∫øn tr√™n."

    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.agents = [
            PRAgent(llm_client),
            LegalAgent(llm_client),
            FinanceAgent(llm_client),
            OpsAgent(llm_client),
        ]

        default_goals = GoalManager.get_default_goals()
        for agent in self.agents:
            agent.set_goal(default_goals.get(agent.name, ""))

    def score_agents(self, context: str):
        context_lower = context.lower()
        keyword_map = {
            "PRAgent": [
                "truy·ªÅn th√¥ng",
                "kh√°ch h√†ng",
                "d∆∞ lu·∫≠n",
                "b√°o ch√≠",
                "ph·∫£n h·ªìi",
                "tuy√™n b·ªë",
                "xin l·ªói",
            ],
            "LegalAgent": [
                "ph√°p l√Ω",
                "vi ph·∫°m",
                "lu·∫≠t",
                "quy ƒë·ªãnh",
                "tr√°ch nhi·ªám",
                "ki·ªán t·ª•ng",
                "tu√¢n th·ªß",
            ],
            "FinanceAgent": [
                "t√†i ch√≠nh",
                "ti·ªÅn",
                "thi·ªát h·∫°i",
                "b·ªìi th∆∞·ªùng",
                "b√°o c√°o",
                "chi ph√≠",
                "l·ªó",
                "doanh thu",
            ],
            "OpsAgent": [
                "h·ªá th·ªëng",
                "v·∫≠n h√†nh",
                "s·ª± c·ªë",
                "h·∫° t·∫ßng",
                "r√≤ r·ªâ",
                "server",
                "k·ªπ thu·∫≠t",
                "kh·∫Øc ph·ª•c",
            ],
        }
        scores = []
        for agent in self.agents:
            agent_key = type(agent).__name__
            keywords = keyword_map.get(agent_key, [])
            score = sum(1 for kw in keywords if kw in context_lower)
            scores.append((agent, score))
        return sorted(scores, key=lambda x: x[1], reverse=True)

    async def run(self, context: str, max_rounds: int = 10, max_cycles: int = 5):
        goals = GoalManager.extract_goals_from_context(context)
        for agent in self.agents:
            new_goal = goals.get(agent.name)
            if new_goal:
                agent.set_goal(new_goal)

        agent_scores = self.score_agents(context)
        tried_agents = set()
        cycle = 0

        soft_consensus_streak = 0  # üëà ƒê·∫øm s·ªë v√≤ng soft-consensus li√™n ti·∫øp

        while cycle < max_cycles:
            lead_agent = next((a for a, _ in agent_scores if a.name not in tried_agents), None)
            if not lead_agent:
                break
            tried_agents.add(lead_agent.name)
            cycle += 1

            context_with_goal = lead_agent.get_goal_context() + context
            lead_response = await lead_agent.speak(context_with_goal)
            yield {"agent": lead_agent.name, "text": lead_response["text"], "type": "lead"}
            opinions = {lead_agent.name: lead_response["text"]}

            for round_num in range(max_rounds):
                round_reviews = {}
                soft_flags = []

                # üëá Merge t·∫•t c·∫£ ph·∫£n h·ªìi hi·ªán c√≥ th√†nh b·∫£n t·ªïng h·ª£p
                merged_input = "\n".join([f"{k}:\n{v}" for k, v in opinions.items()])
                merged_prompt = (
                    "T·ªïng h·ª£p n·ªôi dung sau th√†nh m·ªôt ƒë·ªÅ xu·∫•t r√µ r√†ng, lo·∫°i b·ªè tr√πng l·∫∑p, gi·ªØ m·∫°ch logic:\n\n"
                    f"{merged_input}\n\nƒê·ªÅ xu·∫•t t·ªïng h·ª£p:"
                )
                merged_opinion = ""
                async for chunk in self.llm_client.chat_stream(merged_prompt):
                    merged_opinion += chunk

                yield {
                    "agent": "orchestrator",
                    "text": merged_opinion,
                    "type": f"merged_proposal_cycle_{cycle}_round_{round_num+1}",
                }

                for agent in self.agents:
                    try:
                        buffer = ""
                        prompt = agent.get_goal_context() + merged_opinion
                        async for chunk in agent.review_peer_outputs({"full_input": prompt}):
                            buffer += chunk
                            yield {
                                "agent": agent.name,
                                "text": chunk,
                                "type": f"stream_review_cycle_{cycle}_round_{round_num+1}",
                            }
                        review_text = buffer.strip()
                        round_reviews[agent.name] = review_text
                        yield {
                            "agent": agent.name,
                            "text": review_text,
                            "type": f"review_cycle_{cycle}_round_{round_num+1}",
                        }

                        # üëá Ki·ªÉm tra ph·∫£n h·ªìi c√≥ mang t√≠nh ph·∫£n ƒë·ªëi kh√¥ng
                        if any(word in review_text.lower() for word in ["kh√¥ng ƒë·ªìng √Ω", "ph·∫£n ƒë·ªëi", "ƒë·ªÅ ngh·ªã xem x√©t l·∫°i"]):
                            soft_flags.append(False)
                        else:
                            soft_flags.append(True)

                    except Exception as e:
                        round_reviews[agent.name] = f"[L·ªñI khi ph·∫£n bi·ªán]: {e}"
                        soft_flags.append(False)

                # ‚úÖ N·∫øu t·∫•t c·∫£ ƒë·ªÅu ph·∫£n h·ªìi b·ªï sung (kh√¥ng ph·∫£n ƒë·ªëi) ‚Üí soft consensus
                if all(soft_flags):
                    soft_consensus_streak += 1
                else:
                    soft_consensus_streak = 0

                if soft_consensus_streak >= 2:
                    yield {
                        "agent": "orchestrator",
                        "text": f"‚úÖ ƒê·∫°t soft consensus sau 2 v√≤ng li√™n ti·∫øp.",
                        "type": "soft_consensus_reached",
                    }

                    async for chunk in self._finalize(merged_opinion):
                        yield chunk
                    return

                opinions = round_reviews.copy()

            # ‚úÖ N·∫øu h·∫øt v√≤ng nh∆∞ng c√≥ 3 agent gi·ªëng nhau ‚Üí ch·ªët theo ƒëa s·ªë
            proposal_counter = Counter(opinions.values())
            most_common = proposal_counter.most_common(1)[0] if proposal_counter else None
            if most_common and most_common[1] >= 3:
                yield {
                    "agent": "orchestrator",
                    "text": f"üìå Ph∆∞∆°ng √°n ƒë∆∞·ª£c ƒëa s·ªë (>=3) ƒë·ªìng thu·∫≠n sau chu k·ª≥ {cycle}:\n{most_common[0]}",
                    "type": "final_decision",
                }
                async for chunk in self._finalize(most_common[0]):
                    yield chunk
                return
            else:
                yield {
                    "agent": "orchestrator",
                    "text": f"‚ö†Ô∏è Ch∆∞a ƒë·∫°t ƒë·ªìng thu·∫≠n sau {max_rounds} v√≤ng. Chuy·ªÉn sang lead agent kh√°c.",
                    "type": "no_consensus",
                }

        yield {
            "agent": "orchestrator",
            "text": "‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ agent lead nh∆∞ng kh√¥ng ƒë·∫°t ƒë∆∞·ª£c ƒë·ªìng thu·∫≠n.",
            "type": "final_decision_failed",
        }

        # üëá ConflictResolver: synthesize best-effort
        fallback_proposal = ""
        async for chunk in self.synthesize_best_effort(opinions):
            fallback_proposal += chunk
            yield {"agent": "orchestrator", "text": chunk, "type": "final_fallback_summary"}

        async for chunk in self._finalize(fallback_proposal):
            yield chunk
        
    async def summarize_final_proposal(self, opinions: dict) -> str:
        merged = "\n\n".join(
            [f"{agent}:\n{content}" for agent, content in opinions.items()]
        )

        prompt = (
            "T√¨nh hu·ªëng: C√°c b·ªô ph·∫≠n chuy√™n m√¥n ƒë√£ ho√†n to√†n ƒë·ªìng thu·∫≠n sau nhi·ªÅu v√≤ng ph·∫£n bi·ªán.\n"
            "D∆∞·ªõi ƒë√¢y l√† c√°c √Ω ki·∫øn cu·ªëi c√πng c·ªßa t·ª´ng b·ªô ph·∫≠n:\n\n"
            f"{merged}\n\n"
            "üéØ Y√™u c·∫ßu:\n"
            "- T·ªïng h·ª£p c√°c √Ω ki·∫øn tr√™n th√†nh **m·ªôt b·∫£n ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông th·ªëng nh·∫•t**.\n"
            "- Ng·∫Øn g·ªçn, r√µ r√†ng, mang t√≠nh th·ª±c thi cao.\n"
            "- D√πng gi·ªçng vƒÉn chuy√™n nghi·ªáp, nh·∫•t qu√°n, ph√π h·ª£p ƒë·ªÉ g·ª≠i cho kh√°ch h√†ng, ƒë·ªëi t√°c ho·∫∑c c√¥ng b·ªë n·ªôi b·ªô.\n"
            "- Tr√°nh l·∫∑p l·∫°i, kh√¥ng li·ªát k√™ theo agent. Kh√¥ng c·∫ßn n√≥i 'PRAgent n√≥i r·∫±ng...'\n"
            "- N·∫øu ph√π h·ª£p, h√£y vi·∫øt d∆∞·ªõi d·∫°ng th√¥ng b√°o ch√≠nh th·ª©c ho·∫∑c email d·ª± th·∫£o.\n\n"
            "‚úçÔ∏è B·∫Øt ƒë·∫ßu b·∫£n ƒë·ªÅ xu·∫•t:"
        )

        # Header m·ªü ƒë·∫ßu
        yield "üìÑ B·∫£n ƒë·ªÅ xu·∫•t th·ªëng nh·∫•t:\n"
        # Stream n·ªôi dung t·ª´ LLM
        async for chunk in self.llm_client.chat_stream(prompt):
            yield chunk

    async def synthesize_best_effort(self, opinions: dict) -> str:
        merged = "\n\n".join(f"{agent}:\n{text}" for agent, text in opinions.items())

        prompt = (
            "B·ªëi c·∫£nh: H·ªá th·ªëng AI g·ªìm nhi·ªÅu b·ªô ph·∫≠n chuy√™n m√¥n (PR, Ph√°p l√Ω, T√†i ch√≠nh, V·∫≠n h√†nh) ƒë√£ tranh lu·∫≠n nhi·ªÅu v√≤ng nh∆∞ng **kh√¥ng ƒë·∫°t ƒë∆∞·ª£c ƒë·ªìng thu·∫≠n ho√†n to√†n**.\n"
            "D∆∞·ªõi ƒë√¢y l√† c√°c √Ω ki·∫øn cu·ªëi c√πng c·ªßa t·ª´ng b·ªô ph·∫≠n:\n\n"
            f"{merged}\n\n"
            "üéØ Nhi·ªám v·ª•:\n"
            "- T·ªïng h·ª£p l·∫°i **c√°c ƒëi·ªÉm chung c√≥ gi√° tr·ªã cao nh·∫•t**.\n"
            "- B·ªè qua c√°c ƒëi·ªÉm tranh c√£i kh√¥ng th·ªÉ th·ªëng nh·∫•t.\n"
            "- Vi·∫øt m·ªôt **b·∫£n ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông** r√µ r√†ng, chuy√™n nghi·ªáp, trung l·∫≠p, c√≥ th·ªÉ g·ª≠i cho c·∫•p qu·∫£n l√Ω ra quy·∫øt ƒë·ªãnh.\n"
            "- Gi·ªØ vƒÉn phong kh√°ch quan, tr√°nh quy tr√°ch nhi·ªám c√° nh√¢n, tr√°nh thu·∫≠t l·∫°i ai n√≥i g√¨.\n"
            "- N·∫øu c·∫ßn, ph√¢n t√°ch th√†nh c√°c ph·∫ßn: T√¨nh h√¨nh ‚Äì H√†nh ƒë·ªông ‚Äì Khuy·∫øn ngh·ªã.\n\n"
            "‚úçÔ∏è B·∫Øt ƒë·∫ßu vi·∫øt b·∫£n ƒë·ªÅ xu·∫•t:"
        )

        yield "üìÑ B·∫£n ƒë·ªÅ xu·∫•t t·ªïng h·ª£p (fallback):\n"
        async for chunk in self.llm_client.chat_stream(prompt):
            yield chunk
            
    async def _finalize(self, final_proposal: str):
        # 1. Stream l·∫°i b·∫£n ƒë·ªÅ xu·∫•t
        yield {
            "agent": "orchestrator",
            "text": final_proposal,
            "type": "final_proposal",
        }

        # 2. Tr√≠ch xu·∫•t h√†nh ƒë·ªông
        action_buffer = ""
        async for chunk in extract_actions_stream(self.llm_client, final_proposal):
            action_buffer += chunk
            yield {"agent": "orchestrator", "text": chunk, "type": "action_extraction"}

        try:
            actions = eval(action_buffer)
        except Exception as e:
            yield {
                "agent": "orchestrator",
                "text": f"‚ùå L·ªói parse actions: {e}",
                "type": "error",
            }
            return

        # 3. Th·ª±c thi
        async for chunk in execute_actions_stream(self.llm_client, actions):
            yield {"agent": "orchestrator", "text": chunk, "type": "action_execution"}
